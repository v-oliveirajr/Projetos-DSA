library(readr)
library(data.table)
library(dplyr)
library(ROSE)

# Fazendo a leitura das colunas do dataset
colunas <- fread(file = 'train.csv',header = T,stringsAsFactors = T,nrows = 0)
View(df)

# Carregando o dataset de amostras

df <- fread(file = 'train_sample.csv',header = T,stringsAsFactors = T,drop = 1, data.table=F)
?fread
?select
?ovun.sample
table(df$is_attributed)
View(df)
df <- df%>%
  select(-attributed_time)

100*prop.table(table(df$is_attributed))


table(bal$app)
# A variável-alvo is_attributed está desbalanceada, iremos fazer um oversampling
# para chegarmos a uma proporção 95%-0,5% 

bal <- ovun.sample(is_attributed~., data = df, method = 'over', p = 0.05)
bal <- bal$data
View(bal)

bal2 <- bal
bal[,1] <- bal2[,1]

View(bal2)

# Transformando a coluna "app" para faixas de modelos de aplicativos
# Esta coluna terá 5 faixas de modelos

for (i in 1:nrow(bal)) {
  if(bal2[i,1]<=20)bal[i,1]<-'0-20'
  if((bal2[i,1]>20  & bal2[i,1]<=40)==TRUE)bal[i,1]<-'20-40'
  if((bal2[i,1]>40  & bal2[i,1]<=100)==TRUE)bal[i,1]<-'40-100'
  if((bal2[i,1]>100  & bal2[i,1]<=200)==TRUE)bal[i,1]<-'100-200'
  if(bal2[i,1]>200) bal[i,1]<-'200-550'
  
}

unique(bal$app)
table(bal$app)

table(bal$device)

# Para a coluna device, que indica o tipo de smartphone em uso pelo usuário, pre
# dominam-se os valores 0, 1 e 2
# Então Substituiremos os valores maiores que 2 para "Other"

?mutate
bal %>% mutate(device_n = if (bal[,2]>3){"Other"} else {bal[,2]})%>% View()
bal <- bal %>% mutate(device_n = bal[,2])

for (i in 1:nrow(bal)){
  if(bal[i,2]>3)bal[i,7]<-'Other'
}

unique(bal$device_n)
table(bal$device_n)
bal <- bal%>%select(-device)


View(bal)

# Por fim, também transformaremos a coluna channel em faixas de valores

unique(bal$channel)
View(table(bal$channel))

for (i in 1:nrow(bal)) {
  if(bal2[i,4]<=100)bal[i,3]<-'0-100'
  if((bal2[i,4]>100  & bal2[i,4]<=200)==TRUE)bal[i,3]<-'100-200'
  if((bal2[i,4]>200  & bal2[i,4]<=300)==TRUE)bal[i,3]<-'200-300'
  if((bal2[i,4]>300  & bal2[i,4]<=400)==TRUE)bal[i,3]<-'300-400'
  if(bal2[i,4]>400) bal[i,3]<-'400-500'
  
}

# Salvando o dataset modificado em um arquivo csv

?fwrite
fwrite(bal,file = 'analise_fraude.csv',sep = ',')

# Recarregando o novo arquivo csv

bal <- read.csv('analise_fraude.csv')
View(bal)

# As datas foram desconfiguradas, configurando novamente no formato ANO-MES-DIA
# HORA:MIN:SEG
?as.POSIXct
bal$click_time <- as.POSIXct(bal$click_time,format="%Y-%m-%dT%H:%M:%S")
View(bal)

# Ainda resta a coluna "os" relacionada ao sistema operacional dos smartphones
# Também será colocada em faixas de valores por conter muitos valores únicos
bal2 <- bal
table(bal$os)
length(table(bal$os))
?hist

for (i in 1:nrow(bal)) {
  if(bal2[i,2]<=15)bal[i,2]<-'0-15'
  if((bal2[i,2]>15  & bal2[i,2]<=30)==TRUE)bal[i,2]<-'15-30'
  if((bal2[i,2]>30  & bal2[i,2]<=45)==TRUE)bal[i,2]<-'30-45'
  if(bal2[i,2]>45) bal[i,2]<-'Other'
  
}
unique(bal$os)

# Salvando em um novo arquivo csv

write.csv2(bal, file = "analise_fraude2.csv")


# Análise exploratória após as mudanças

require(ggplot2)
?qplot
library(gridExtra)
?geom_bar
plot1 <- ggplot(bal,aes(x = os)) + geom_bar()
plot2 <- ggplot(bal,aes(x = app)) + geom_bar()
plot3 <- ggplot(bal, aes(x = channel)) + geom_bar()
plot4 <- ggplot(bal, aes(x = device_n)) + geom_bar()

grid.arrange(plot1,plot2,plot3,plot4, ncol = 2)

# Algumas variáveis preditoras (principalmente app e device_n) estão desbalance-
# adas, poderá isto causar perda de precisão?
table(bal$app)

# Recarregando

bal <- read.csv2('analise_fraude2.csv')
View(bal)
bal <- bal[,-1]

# Vamos extrair da coluna click_time apenas valores que variam, como dia e tempo

class(bal$click_time)
bal$click_time <- as.POSIXlt(bal$click_time)
unclass(bal$click_time)

bal$day <- bal$click_time$mday
?POSIXt
bal$time <- strftime(bal$click_time,format = '%H:%M:%S')

# Com isso, sabemos que todos os valores se referem à 11/2017, podemos deletar 
# a coluna click_time

bal <- bal[,-4]
View(bal)
ggplot(bal,aes(x = day)) + geom_bar() + xlab('Nov/2017') + ylab(NULL) +
  ggtitle('Número de cliques por dia de novembro de 2017')
?ggtitle

# Criação do modelo

library(randomForest)
class(bal$is_attributed)
bal$is_attributed <- as.factor(bal$is_attributed)
modelo1 <- randomForest(is_attributed ~ app + os + channel + device_n,
                        data = bal,
                        mtry = 2,
                        ntree = 200,
                        importance = TRUE)

1+1
modelo1
?varImpPlot
varImpPlot(modelo1, main = 'Nível de importância das variáveis preditoras')

# Observa-se que 'os' parece ser a única variável com relativo baixo nível de im
# portância frente as demais 

# Escolhemos manter todas as variáveis preditoras

?setdiff
bal$is_attributed <- sapply(bal$is_attributed, function(x){ifelse(x == 'Nao','0','1')})
dtreino <- bal %>% slice_sample(prop = 0.75,replace = T)
?slice_sample

dteste <- bal %>% slice_sample(prop = 0.25,replace = T)
str(dteste)
head(dtreino)
head(dteste)

modelo2 <- randomForest(is_attributed ~ app + os + channel + device_n,
                        data = dtreino,
                        mtry = 2,
                        ntree = 500,
                        importance = TRUE)
modelo2


# Agora retiraremos 'os' para testar como fica a taxa de erro

modelo2.1 <- randomForest(is_attributed ~ app  + channel + device_n,
                        data = dtreino,
                        mtry = 2,
                        ntree = 500)
modelo2.1

# A taxa de erro aumentou, de fato retirar 'os' não é uma boa alternativa

# Utilizando outro modelo de classificação - knn - K-nearest neighbor

library(class)
?knn

dtreino <- dtreino[,-6]
dtreino <- dtreino[,-6]
?relocate

dteste2 <- relocate(dteste,device_n,.before = is_attributed)
head(dteste2)
dtreino2 <- relocate(dtreino,device_n,.before = is_attributed)
head(dtreino2)
modelo3 <- knn(train = dtreino2[,-5],test = dteste2[,1:4] ,cl = dtreino2[,5],k = 5)

# Erro! O knn pede que as variáveis preditoras sejam numéricas (e normalizadas)
# Modelo descartado

# Utilizando o método Naive Bayes

library(e1071)
?naiveBayes
modelo3 <- naiveBayes(is_attributed ~ app  + os + channel + device_n, 
                      data = dtreino)
modelo3
str(dteste)
dteste2
dteste <- dteste[-6:-7]
# Fazendo as previsões



dteste2
predict3 <- predict(modelo3,newdata = dteste)
dteste$Previsao <- predict3
table(dteste$Previsao)
table(dteste$is_attributed)
cm <- table(dteste$is_attributed,dteste$Previsao)


library(caret)
confusionMatrix(cm)

predict2 <- predict(modelo2,newdata = dteste)
cm2 <- table(dteste$is_attributed,predict2)
confusionMatrix(cm2)

# O modelo RandomForest produz uma acurácia melhor, assim como outros atributos
