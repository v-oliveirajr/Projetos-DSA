---
title: "Análise de fraude em cliques para download de aplicativo"
author: "Vanderlei Oliveira"
date: "3/27/2021"
output:
  pdf_document: default
  html_document: default
---


# Carregamento dos dados

```{r df}

library(readr)
library(data.table)
library(dplyr)
library(ROSE)

df <- fread(file = 'train_sample.csv',header = T,stringsAsFactors = T,drop = 1, data.table=F)
table(df$is_attributed)
View(df)
df <- df%>%
  select(-attributed_time)

100*prop.table(table(df$is_attributed))


```
<p style = "font-size:11pt">
# A variável-alvo is_attributed está desbalanceada, iremos fazer um oversampling para chegarmos a uma proporção 95%-0,5% 

```{r bal, echo=FALSE}
bal <- ovun.sample(is_attributed~., data = df, method = 'over', p = 0.05)
bal <- bal$data
View(bal)

bal2 <- bal
bal[,1] <- bal2[,1]

View(bal2)
```

# Transformando a coluna "app" para faixas de modelos de aplicativos
# Esta coluna terá 5 faixas de modelos

```{r loop for}
for (i in 1:nrow(bal)) {
  if(bal2[i,1]<=20)bal[i,1]<-'0-20'
  if((bal2[i,1]>20  & bal2[i,1]<=40)==TRUE)bal[i,1]<-'20-40'
  if((bal2[i,1]>40  & bal2[i,1]<=100)==TRUE)bal[i,1]<-'40-100'
  if((bal2[i,1]>100  & bal2[i,1]<=200)==TRUE)bal[i,1]<-'100-200'
  if(bal2[i,1]>200) bal[i,1]<-'200-550'
  
}

unique(bal$app)
table(bal$app)

table(bal$device)
```

# Para a coluna device, que indica o tipo de smartphone em uso pelo usuário, predominam-se os valores 0, 1 e 2
# Então Substituiremos os valores maiores que 2 para "Other"

```{r}

bal <- bal %>% mutate(device_n = bal[,2])

for (i in 1:nrow(bal)){
  if(bal[i,2]>3)bal[i,7]<-'Other'
}

unique(bal$device_n)
table(bal$device_n)
bal <- bal%>%select(-device)
head(bal)
```

# Ainda resta a coluna "os" relacionada ao sistema operacional dos smartphones
# Também será colocada em faixas de valores por conter muitos valores únicos


```{r}
bal2 <- bal
table(bal$os)
length(table(bal$os))

for (i in 1:nrow(bal)) {
  if(bal2[i,2]<=15)bal[i,2]<-'0-15'
  if((bal2[i,2]>15  & bal2[i,2]<=30)==TRUE)bal[i,2]<-'15-30'
  if((bal2[i,2]>30  & bal2[i,2]<=45)==TRUE)bal[i,2]<-'30-45'
  if(bal2[i,2]>45) bal[i,2]<-'Other'
  
}
unique(bal$os)

```

# Por fim, também transformaremos a coluna channel em faixas de valores</p>

```{r}
unique(bal$channel)
View(table(bal$channel))
View(bal2)
for (i in 1:nrow(bal)) {
  if(bal2[i,3]<=100)bal[i,3]<-'0-100'
  if((bal2[i,3]>100  & bal2[i,3]<=200)==TRUE)bal[i,3]<-'100-200'
  if((bal2[i,3]>200  & bal2[i,3]<=300)==TRUE)bal[i,3]<-'200-300'
  if((bal2[i,3]>300  & bal2[i,3]<=400)==TRUE)bal[i,3]<-'300-400'
  if(bal2[i,3]>400) bal[i,3]<-'400-500'
  
}
unique(bal$channel)
```

# Análise exploratória após as mudanças

```{r}
require(ggplot2)
library(gridExtra)
plot1 <- ggplot(bal,aes(x = os)) + geom_bar()
plot2 <- ggplot(bal,aes(x = app)) + geom_bar()
plot3 <- ggplot(bal, aes(x = channel)) + geom_bar()
plot4 <- ggplot(bal, aes(x = device_n)) + geom_bar()

grid.arrange(plot1,plot2,plot3,plot4, ncol = 2)
```
<p style = "font-size:11pt">
# Algumas variáveis preditoras (principalmente app e device_n) estão desbalanceadas, poderá isto causar perda de precisão?

```{r}
table(bal$app)
```


# Criação do modelo

```{r}
library(randomForest)
head(bal)
class(bal$is_attributed)
bal$is_attributed <- as.factor(bal$is_attributed)
bal$app <- as.factor(bal$app)
bal$os <- as.factor(bal$os)
bal$channel <- as.factor(bal$channel)
bal$device_n <- as.factor(bal$device_n)
modelo1 <- randomForest(is_attributed ~ app + os + channel + device_n,
                        data = bal,
                        mtry = 2,
                        ntree = 200,
                        importance = TRUE)
modelo1
varImpPlot(modelo1, main = 'Nível de importância das variáveis preditoras')
```

# Observa-se que 'os' parece ser a única variável com relativo baixo nível de importância frente as demais 

# Escolhemos manter todas as variáveis preditoras
# Dividindo em dados de treino e de teste

```{r}
dtreino <- bal %>% slice_sample(prop = 0.75,replace = T)
dteste <- bal %>% slice_sample(prop = 0.25,replace = T)
str(dteste)
str(dtreino)
```

# Criação da segunda versão, agora com dados divididos

```{r}
modelo2 <- randomForest(is_attributed ~ app + os + channel + device_n,
                        data = dtreino,
                        mtry = 2,
                        ntree = 500,
                        importance = TRUE)
modelo2
```

# Retiraremos 'os' para testar como fica a taxa de erro, visto que é a variável com menor nível de importância

```{r}
modelo2.1 <- randomForest(is_attributed ~ app  + channel + device_n,
                        data = dtreino,
                        mtry = 2,
                        ntree = 500)
modelo2.1
```

# A taxa de erro aumentou, de fato retirar 'os' não é uma boa alternativa

# Utilizando o método Naive Bayes

```{r}
library(e1071)
modelo3 <- naiveBayes(is_attributed ~ app  + os + channel + device_n, 
                      data = dtreino)
modelo3
```

# Fazendo as previsões

```{r}
predict3 <- predict(modelo3,newdata = dteste)
dteste$Previsao <- predict3
table(dteste$Previsao)
table(dteste$is_attributed)
cm <- table(dteste$is_attributed,dteste$Previsao)


library(caret)
confusionMatrix(cm)

predict2 <- predict(modelo2,newdata = dteste)
cm2 <- table(dteste$is_attributed,predict2)
confusionMatrix(cm2)
```

# O modelo RandomForest possui uma acurácia melhor, assim como outros atributos